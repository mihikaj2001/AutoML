{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import requests\nimport tabulate\nimport future\n\nimport pandas as pd\nimport numpy as np\n\n# pd.read_csv(\"/kaggle/input/clean-creditcard-train-data/clean-credit-train.csv\")\n# !pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T06:20:16.204136Z","iopub.execute_input":"2023-05-17T06:20:16.204552Z","iopub.status.idle":"2023-05-17T06:20:16.263498Z","shell.execute_reply.started":"2023-05-17T06:20:16.204515Z","shell.execute_reply":"2023-05-17T06:20:16.262448Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Required for plotting:\nimport matplotlib\nimport h2o\nfrom h2o.automl import H2OAutoML\n\n# Start the H2O cluster (locally)\nh2o.init()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T06:20:16.265326Z","iopub.execute_input":"2023-05-17T06:20:16.265632Z","iopub.status.idle":"2023-05-17T06:20:24.082967Z","shell.execute_reply.started":"2023-05-17T06:20:16.265606Z","shell.execute_reply":"2023-05-17T06:20:24.082059Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"h2o:1: DeprecationWarning: Your Python version is 3.10.10. The support for this version will be removed in H2O 3.42.0.1.\n","output_type":"stream"},{"name":"stdout","text":"Checking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"11.0.18\" 2023-01-17; OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1); OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmpmt0_4jia\n  JVM stdout: /tmp/tmpmt0_4jia/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmpmt0_4jia/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ----------------------------------\nH2O_cluster_uptime:         02 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.40.0.3\nH2O_cluster_version_age:    1 month and 12 days\nH2O_cluster_name:           H2O_from_python_unknownUser_6dr5jc\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    7.500 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.10 final\n--------------------------  ----------------------------------","text/html":"\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>02 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.40.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 12 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_unknownUser_6dr5jc</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.500 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.10 final</td></tr></tbody>\n  </table>\n</div>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Import Data","metadata":{}},{"cell_type":"code","source":"# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"/kaggle/input/clean-creditcard-train-data/clean-credit-train.csv\")\ntest = h2o.import_file(\"/kaggle/input/clean-creditcard-test-data/clean-credit-test.csv\")\n\n# Identify predictors and response\nx = train.columns\nprint(x)\ny = \"Class\"\nx.remove(y)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T06:22:21.591865Z","iopub.execute_input":"2023-05-17T06:22:21.592332Z","iopub.status.idle":"2023-05-17T06:22:23.846170Z","shell.execute_reply.started":"2023-05-17T06:22:21.592299Z","shell.execute_reply":"2023-05-17T06:22:23.845189Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Convert the target to factor (Categorical)","metadata":{}},{"cell_type":"code","source":"# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T06:33:49.025546Z","iopub.execute_input":"2023-05-17T06:33:49.025900Z","iopub.status.idle":"2023-05-17T06:33:49.031920Z","shell.execute_reply.started":"2023-05-17T06:33:49.025872Z","shell.execute_reply":"2023-05-17T06:33:49.030813Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"# Run AutoML for 20 base models\naml = H2OAutoML(max_models=3, seed=1)\naml.train(x=x, y=y, training_frame=train)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T06:36:22.521587Z","iopub.execute_input":"2023-05-17T06:36:22.521981Z","iopub.status.idle":"2023-05-17T07:24:53.858883Z","shell.execute_reply.started":"2023-05-17T06:36:22.521950Z","shell.execute_reply":"2023-05-17T07:24:53.858042Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_2_20230517_63622\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    163                163                         766771                 15           15           15            108           710           369.485\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 5.022656839270833e-09\nRMSE: 7.087070508518194e-05\nLogLoss: 2.7328193386006475e-06\nMean Per-Class Error: 0.0\nAUC: 1.0\nAUCPR: 1.0\nGini: 1.0\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999251145067237\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284315  0       0        (0.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284315  284315  0        (0.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999925     1         69\nmax f2                       0.999925     1         69\nmax f0point5                 0.999925     1         69\nmax accuracy                 0.999925     1         69\nmax precision                1            1         0\nmax recall                   0.999925     1         69\nmax specificity              1            1         0\nmax absolute_mcc             0.999925     1         69\nmax min_per_class_accuracy   0.999925     1         69\nmax mean_per_class_accuracy  0.999925     1         69\nmax tns                      1            284315    0\nmax fns                      1            248119    0\nmax fps                      1.39826e-07  284315    399\nmax tps                      0.999925     284315    69\nmax tnr                      1            1         0\nmax fnr                      1            0.872691  0\nmax fpr                      1.39826e-07  1         399\nmax tpr                      0.999925     1         69\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.00 %\ngroup    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------  --------------------\n1        0.0103406                   1                  2       2                  1                1            1                           1                   0.0206813       0.0206813                  100     100                0.0206813\n2        0.0203735                   1                  2       2                  1                1            1                           1                   0.0200658       0.0407471                  100     100                0.0407471\n3        0.030176                    1                  2       2                  1                1            1                           1                   0.019605        0.0603521                  100     100                0.0603521\n4        0.0403795                   1                  2       2                  1                1            1                           1                   0.0204069       0.080759                   100     100                0.080759\n5        0.050532                    1                  2       2                  1                1            1                           1                   0.0203049       0.101064                   100     100                0.101064\n6        0.100492                    1                  2       2                  1                1            1                           1                   0.0999209       0.200985                   100     100                0.200985\n7        0.15043                     1                  2       2                  1                1            1                           1                   0.0998751       0.30086                    100     100                0.30086\n8        0.200557                    1                  2       2                  1                1            1                           1                   0.100255        0.401115                   100     100                0.401115\n9        0.300684                    0.999999           2       2                  1                1            1                           1                   0.200253        0.601368                   100     100                0.601368\n10       0.400623                    0.999998           2       2                  1                0.999999     1                           1                   0.199877        0.801245                   100     100                0.801245\n11       0.5                         0.512797           2       2                  1                0.999989     1                           0.999997            0.198755        1                          100     100                1\n12       0.6                         1.26408e-06        0       1.66667            0                1.2205e-05   0.833333                    0.833333            0               1                          -100    66.6667            0.8\n13       0.700002                    8.13358e-07        0       1.42857            0                9.96208e-07  0.714284                    0.714284            0               1                          -100    42.8568            0.599996\n14       0.800004                    6.14536e-07        0       1.24999            0                7.0566e-07   0.624997                    0.624997            0               1                          -100    24.9995            0.399993\n15       0.9                         4.61838e-07        0       1.11111            0                5.38762e-07  0.555556                    0.555556            0               1                          -100    11.1111            0.2\n16       1                           7.6676e-09         0       1                  0                3.54251e-07  0.5                         0.5                 0               1                          -100    0                  0\n\nModelMetricsBinomial: gbm\n** Reported on cross-validation data. **\n\nMSE: 5.28519684336538e-05\nRMSE: 0.007269935930505426\nLogLoss: 0.00034703292888788734\nMean Per-Class Error: 1.2310289643529185e-05\nAUC: 0.9999978008850409\nAUCPR: 0.9999975406058657\nGini: 0.9999956017700817\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9998410272152997\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284308  7       0        (7.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284308  284322  0        (7.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999841     0.999988  66\nmax f2                       0.999841     0.999995  66\nmax f0point5                 0.999841     0.99998   66\nmax accuracy                 0.999841     0.999988  66\nmax precision                1            1         0\nmax recall                   0.999841     1         66\nmax specificity              1            1         0\nmax absolute_mcc             0.999841     0.999975  66\nmax min_per_class_accuracy   0.999841     0.999975  66\nmax mean_per_class_accuracy  0.999841     0.999988  66\nmax tns                      1            284315    0\nmax fns                      1            202390    0\nmax fps                      1.42627e-07  284315    399\nmax tps                      0.999841     284315    66\nmax tnr                      1            1         0\nmax fnr                      1            0.711851  0\nmax fpr                      1.42627e-07  1         399\nmax tpr                      0.999841     1         66\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.01 %\ngroup    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n1        0.0115365                   1                  2        2                  1                1            1                           1                   0.023073        0.023073                   100      100                0.023073\n2        0.0239752                   1                  2        2                  1                1            1                           1                   0.0248773       0.0479503                  100      100                0.0479503\n3        0.0395952                   1                  2        2                  1                1            1                           1                   0.03124         0.0791903                  100      100                0.0791903\n4        0.0531945                   1                  2        2                  1                1            1                           1                   0.0271987       0.106389                   100      100                0.106389\n5        0.104474                    1                  2        2                  1                1            1                           1                   0.102559        0.208948                   100      100                0.208948\n6        0.151923                    1                  2        2                  1                1            1                           1                   0.0948983       0.303846                   100      100                0.303846\n7        0.202161                    1                  2        2                  1                1            1                           1                   0.100477        0.404323                   100      100                0.404323\n8        0.300918                    0.999999           2        2                  1                0.999999     1                           1                   0.197513        0.601836                   100      100                0.601836\n9        0.400067                    0.999998           1.99996  1.99999            0.999982         0.999999     0.999996                    0.999999            0.198294        0.80013                    99.9965  99.9991            0.800127\n10       0.500012                    0.999841           1.99979  1.99995            0.999894         0.999987     0.999975                    0.999997            0.19987         1                          99.9789  99.9951            0.999975\n11       0.600353                    1.87e-06           0        1.66569            0                0.000529523  0.832843                    0.832949            0               1                          -100     66.5685            0.799293\n12       0.700257                    1.02e-06           0        1.42805            0                1.42028e-06  0.714024                    0.714115            0               1                          -100     42.8048            0.599486\n13       0.803433                    4e-07              0        1.24466            0                6.43974e-07  0.62233                     0.622409            0               1                          -100     24.4659            0.393134\n14       0.904356                    2.2e-07            0        1.10576            0                2.9427e-07   0.55288                     0.55295             0               1                          -100     10.5759            0.191288\n15       1                           1e-08              0        1                  0                1.48704e-07  0.5                         0.500064            0               1                          -100     0                  0\n\nCross-Validation Metrics Summary: \n                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.999989     3.93238e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nauc                      0.999998     3.0045e-06   0.999993      0.999996      0.999999      1             1\nerr                      1.05517e-05  3.93238e-06  8.79306e-06   1.75861e-05   8.79306e-06   8.79306e-06   8.79306e-06\nerr_count                1.2          0.447214     1             2             1             1             1\nf0point5                 0.999983     6.29007e-06  0.999986      0.999972      0.999986      0.999986      0.999986\nf1                       0.999989     3.93131e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nf2                       0.999996     1.57248e-06  0.999996      0.999993      0.999996      0.999996      0.999996\nlift_top_group           2            0.000348185  2.00046       1.99979       2.00011       2.00011       1.99954\nlogloss                  0.000351323  0.000151033  0.000451642   0.000558287   0.000308915   0.00024597    0.000191799\nmax_per_class_error      2.11037e-05  7.86662e-06  1.75821e-05   3.5176e-05    1.75852e-05   1.75852e-05   1.75901e-05\nmcc                      0.999979     7.86452e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nmean_per_class_accuracy  0.999989     3.93329e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nmean_per_class_error     1.05519e-05  3.93331e-06  8.79105e-06   1.7588e-05    8.7926e-06    8.7926e-06    8.79507e-06\nmse                      5.17228e-05  2.36595e-05  7.30121e-05   7.26092e-05   5.87986e-05   3.36802e-05   2.05139e-05\npr_auc                   0.999997     3.80841e-06  0.999991      0.999996      0.999999      1             1\nprecision                0.999979     7.86249e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nr2                       0.999793     9.46379e-05  0.999708      0.99971       0.999765      0.999865      0.999918\nrecall                   1            0            1             1             1             1             1\nrmse                     0.0070133    0.00178057   0.00854471    0.00852111    0.00766802    0.00580346    0.00452922\nspecificity              0.999979     7.86664e-06  0.999982      0.999965      0.999982      0.999982      0.999982\n\nScoring History: \n     timestamp            duration           number_of_trees    training_rmse           training_logloss        training_auc        training_pr_auc     training_lift    training_classification_error\n---  -------------------  -----------------  -----------------  ----------------------  ----------------------  ------------------  ------------------  ---------------  -------------------------------\n     2023-05-17 07:19:55  12 min 24.175 sec  0.0                0.5                     0.6931471805594906      0.5                 0.5                 1.0              0.5\n     2023-05-17 07:20:00  12 min 29.378 sec  5.0                0.3027539076569943      0.3602735758590258      0.9999583736599278  0.9999549519021839  2.0              0.0003657914636934386\n     2023-05-17 07:20:04  12 min 33.804 sec  10.0               0.18463969334455507     0.20329722217602272     0.9999718745969037  0.9999686281391038  2.0              0.00017058544220319012\n     2023-05-17 07:20:09  12 min 38.447 sec  15.0               0.11410464082101325     0.11965766447485039     0.9999777823025563  0.9999752353590851  2.0              0.00014244763730369484\n     2023-05-17 07:20:13  12 min 42.894 sec  20.0               0.07138108330623394     0.07185105158083227     0.999980356446807   0.9999776805877443  2.0              0.00011255121959798112\n     2023-05-17 07:20:18  12 min 47.319 sec  25.0               0.046061955280494817    0.043845401522722725    0.9999806441006015  0.999976224745567   2.0              0.00010199954276067039\n     2023-05-17 07:20:22  12 min 51.737 sec  30.0               0.031112452481983334    0.027053597850049866    0.9999868172790677  0.9999849079339339  2.0              6.331006102386438e-05\n     2023-05-17 07:20:27  12 min 56.207 sec  35.0               0.022542550826428295    0.016914393938143465    0.9999870962361362  0.9999850721470551  2.0              5.627560979899056e-05\n     2023-05-17 07:20:31  13 min  0.873 sec  40.0               0.01766341943799046     0.010655517859075214    0.9999898275585523  0.9999876122116917  2.0              3.693086893058755e-05\n     2023-05-17 07:20:36  13 min  5.344 sec  45.0               0.014589120101518471    0.006795877655729194    0.9999930655673077  0.9999921776834312  2.0              2.9896417705713734e-05\n---  ---                  ---                ---                ---                     ---                     ---                 ---                 ---              ---\n     2023-05-17 07:21:40  14 min  9.354 sec  120.0              0.00065306377424895     3.16432556309842e-05    1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:44  14 min 13.724 sec  125.0              0.0005084018965388476   2.3808421309119888e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:48  14 min 17.850 sec  130.0              0.00038844359738230647  1.7968339872344618e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:52  14 min 21.987 sec  135.0              0.0003073750563567389   1.3719138034083516e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:57  14 min 26.099 sec  140.0              0.0002405969824860052   1.0488524185782484e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:01  14 min 30.231 sec  145.0              0.00018904533995990288  7.854240501567559e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:05  14 min 34.370 sec  150.0              0.00014462769065615446  5.797557939228732e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:09  14 min 38.566 sec  155.0              0.00010567787499643689  4.2219134693428804e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:13  14 min 43.001 sec  160.0              7.900020814711673e-05   3.1864422688417992e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:16  14 min 45.568 sec  163.0              7.087070508518194e-05   2.7328193386006475e-06  1.0                 1.0                 2.0              0.0\n[34 rows x 10 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance      percentage\n----------  ---------------------  ---------------------  ---------------------\nV14         249937.859375          1.0                    0.35021734738652266\nV10         212824.109375          0.8515080904797399     0.2982129047259776\nV11         77671.3359375          0.31076258767569914    0.10883444912275503\nV4          36254.71875            0.14505493021609184    0.050800752885616834\nV17         28100.43359375         0.11242968017737909    0.03937482435923682\nV12         12264.8359375          0.04907154109493341    0.017185704954436318\nV26         9074.3583984375        0.03630645801772103    0.012715151419966406\nV3          8412.37109375          0.03365785045445358    0.011787563104891001\nV13         8358.12109375          0.03344079650298077    0.01171154704576643\nV8          6165.67724609375       0.02466884073309972    0.008639455964646785\n---         ---                    ---                    ---\nV9          3120.103515625         0.01248351699669349    0.004371944208636565\nV22         3079.070556640625      0.01231934435359339    0.004314448101056613\nV23         2943.304443359375      0.011776144881449596   0.004124210222820654\nV6          2751.612060546875      0.01100918471266264    0.003855607466956967\nV21         2601.30712890625       0.010407815508267273   0.003644997539393678\nV5          2238.633544921875      0.008956760494467907   0.0031368129015489493\nV24         1781.650146484375      0.007128372432010132   0.0024964796843218034\nV27         1344.9044189453125     0.0053809551794530425  0.0018845038493538148\nV28         1290.6734619140625     0.005163977418793409   0.00180851447357373\nV2          1205.940185546875      0.004824960046319013   0.0016897847086677982\n[29 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_2_20230517_63622\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-2.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-2 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-2 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-2 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-2 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-2 .h2o-table th,\n#h2o-table-2 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-2 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-2\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th>\n<th>number_of_internal_trees</th>\n<th>model_size_in_bytes</th>\n<th>min_depth</th>\n<th>max_depth</th>\n<th>mean_depth</th>\n<th>min_leaves</th>\n<th>max_leaves</th>\n<th>mean_leaves</th></tr></thead>\n    <tbody><tr><td></td>\n<td>163.0</td>\n<td>163.0</td>\n<td>766771.0</td>\n<td>15.0</td>\n<td>15.0</td>\n<td>15.0</td>\n<td>108.0</td>\n<td>710.0</td>\n<td>369.48465</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 5.022656839270833e-09\nRMSE: 7.087070508518194e-05\nLogLoss: 2.7328193386006475e-06\nMean Per-Class Error: 0.0\nAUC: 1.0\nAUCPR: 1.0\nGini: 1.0</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-3.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-3 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-3 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-3 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-3 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-3 .h2o-table th,\n#h2o-table-3 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-3 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-3\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999251145067237</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>1</td>\n<td>0.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>Total</td>\n<td>284315.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/568630.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-4.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-4 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-4 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-4 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-4 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-4 .h2o-table th,\n#h2o-table-4 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-4 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-4\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max f2</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9999999</td>\n<td>284315.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9999999</td>\n<td>248119.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0000001</td>\n<td>284315.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.9999251</td>\n<td>284315.0</td>\n<td>69.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9999999</td>\n<td>0.8726905</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0000001</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-5.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-5 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-5 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-5 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-5 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-5 .h2o-table th,\n#h2o-table-5 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-5 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-5\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.00 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0103406</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0206813</td>\n<td>0.0206813</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0206813</td></tr>\n<tr><td>2</td>\n<td>0.0203735</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0200658</td>\n<td>0.0407471</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0407471</td></tr>\n<tr><td>3</td>\n<td>0.0301760</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0196050</td>\n<td>0.0603521</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0603521</td></tr>\n<tr><td>4</td>\n<td>0.0403795</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0204069</td>\n<td>0.0807590</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0807590</td></tr>\n<tr><td>5</td>\n<td>0.0505320</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0203049</td>\n<td>0.1010640</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.1010640</td></tr>\n<tr><td>6</td>\n<td>0.1004924</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0999209</td>\n<td>0.2009848</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.2009848</td></tr>\n<tr><td>7</td>\n<td>0.1504300</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>0.0998751</td>\n<td>0.3008600</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.3008600</td></tr>\n<tr><td>8</td>\n<td>0.2005575</td>\n<td>0.9999997</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>0.1002550</td>\n<td>0.4011150</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.4011150</td></tr>\n<tr><td>9</td>\n<td>0.3006841</td>\n<td>0.9999994</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999996</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>0.2002532</td>\n<td>0.6013682</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.6013682</td></tr>\n<tr><td>10</td>\n<td>0.4006225</td>\n<td>0.9999978</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999988</td>\n<td>1.0</td>\n<td>0.9999995</td>\n<td>0.1998769</td>\n<td>0.8012451</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.8012451</td></tr>\n<tr><td>11</td>\n<td>0.5</td>\n<td>0.5127973</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999894</td>\n<td>1.0</td>\n<td>0.9999975</td>\n<td>0.1987549</td>\n<td>1.0</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>1.0</td></tr>\n<tr><td>12</td>\n<td>0.6</td>\n<td>0.0000013</td>\n<td>0.0</td>\n<td>1.6666667</td>\n<td>0.0</td>\n<td>0.0000122</td>\n<td>0.8333333</td>\n<td>0.8333333</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>66.6666667</td>\n<td>0.8</td></tr>\n<tr><td>13</td>\n<td>0.7000018</td>\n<td>0.0000008</td>\n<td>0.0</td>\n<td>1.4285678</td>\n<td>0.0</td>\n<td>0.0000010</td>\n<td>0.7142839</td>\n<td>0.7142840</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>42.8567840</td>\n<td>0.5999965</td></tr>\n<tr><td>14</td>\n<td>0.8000035</td>\n<td>0.0000006</td>\n<td>0.0</td>\n<td>1.2499945</td>\n<td>0.0</td>\n<td>0.0000007</td>\n<td>0.6249973</td>\n<td>0.6249974</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>24.9994504</td>\n<td>0.3999930</td></tr>\n<tr><td>15</td>\n<td>0.9</td>\n<td>0.0000005</td>\n<td>0.0</td>\n<td>1.1111111</td>\n<td>0.0</td>\n<td>0.0000005</td>\n<td>0.5555556</td>\n<td>0.5555558</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>11.1111111</td>\n<td>0.2000000</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0000000</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.0000004</td>\n<td>0.5</td>\n<td>0.5000002</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on cross-validation data. **\n\nMSE: 5.28519684336538e-05\nRMSE: 0.007269935930505426\nLogLoss: 0.00034703292888788734\nMean Per-Class Error: 1.2310289643529185e-05\nAUC: 0.9999978008850409\nAUCPR: 0.9999975406058657\nGini: 0.9999956017700817</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-6.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-6 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-6 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-6 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-6 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-6 .h2o-table th,\n#h2o-table-6 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-6 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-6\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9998410272152997</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>284308.0</td>\n<td>7.0</td>\n<td>0.0</td>\n<td> (7.0/284315.0)</td></tr>\n<tr><td>1</td>\n<td>0.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>Total</td>\n<td>284308.0</td>\n<td>284322.0</td>\n<td>0.0</td>\n<td> (7.0/568630.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-7.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-7 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-7 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-7 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-7 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-7 .h2o-table th,\n#h2o-table-7 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-7 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-7\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max f2</td>\n<td>0.9998410</td>\n<td>0.9999951</td>\n<td>66.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.9998410</td>\n<td>0.9999803</td>\n<td>66.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.9998410</td>\n<td>1.0</td>\n<td>66.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.9998410</td>\n<td>0.9999754</td>\n<td>66.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.9998410</td>\n<td>0.9999754</td>\n<td>66.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9999999</td>\n<td>284315.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9999999</td>\n<td>202390.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0000001</td>\n<td>284315.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.9998410</td>\n<td>284315.0</td>\n<td>66.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9999999</td>\n<td>0.7118513</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0000001</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.9998410</td>\n<td>1.0</td>\n<td>66.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-8.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-8 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-8 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-8 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-8 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-8 .h2o-table th,\n#h2o-table-8 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-8 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-8\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.01 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0115365</td>\n<td>1.0000000</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0230730</td>\n<td>0.0230730</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0230730</td></tr>\n<tr><td>2</td>\n<td>0.0239752</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0248773</td>\n<td>0.0479503</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0479503</td></tr>\n<tr><td>3</td>\n<td>0.0395952</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0312400</td>\n<td>0.0791903</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0791903</td></tr>\n<tr><td>4</td>\n<td>0.0531945</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0271987</td>\n<td>0.1063890</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.1063890</td></tr>\n<tr><td>5</td>\n<td>0.1044739</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.1025588</td>\n<td>0.2089478</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.2089478</td></tr>\n<tr><td>6</td>\n<td>0.1519230</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0948983</td>\n<td>0.3038461</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.3038461</td></tr>\n<tr><td>7</td>\n<td>0.2021613</td>\n<td>0.9999996</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.1004766</td>\n<td>0.4043227</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.4043227</td></tr>\n<tr><td>8</td>\n<td>0.3009180</td>\n<td>0.9999992</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999994</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>0.1975133</td>\n<td>0.6018360</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.6018360</td></tr>\n<tr><td>9</td>\n<td>0.4000668</td>\n<td>0.9999976</td>\n<td>1.9999645</td>\n<td>1.9999912</td>\n<td>0.9999823</td>\n<td>0.9999986</td>\n<td>0.9999956</td>\n<td>0.9999994</td>\n<td>0.1982941</td>\n<td>0.8001301</td>\n<td>99.9964526</td>\n<td>99.9991208</td>\n<td>0.8001266</td></tr>\n<tr><td>10</td>\n<td>0.5000123</td>\n<td>0.9998410</td>\n<td>1.9997889</td>\n<td>1.9999508</td>\n<td>0.9998944</td>\n<td>0.9999867</td>\n<td>0.9999754</td>\n<td>0.9999969</td>\n<td>0.1998699</td>\n<td>1.0</td>\n<td>99.9788851</td>\n<td>99.9950760</td>\n<td>0.9999754</td></tr>\n<tr><td>11</td>\n<td>0.6003535</td>\n<td>1.87e-06</td>\n<td>0.0</td>\n<td>1.6656854</td>\n<td>0.0</td>\n<td>0.0005295</td>\n<td>0.8328427</td>\n<td>0.8329491</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>66.5685353</td>\n<td>0.7992930</td></tr>\n<tr><td>12</td>\n<td>0.7002568</td>\n<td>1.02e-06</td>\n<td>0.0</td>\n<td>1.4280476</td>\n<td>0.0</td>\n<td>0.0000014</td>\n<td>0.7140238</td>\n<td>0.7141153</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>42.8047626</td>\n<td>0.5994865</td></tr>\n<tr><td>13</td>\n<td>0.8034328</td>\n<td>4e-07</td>\n<td>0.0</td>\n<td>1.2446591</td>\n<td>0.0</td>\n<td>0.0000006</td>\n<td>0.6223296</td>\n<td>0.6224094</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>24.4659149</td>\n<td>0.3931344</td></tr>\n<tr><td>14</td>\n<td>0.9043561</td>\n<td>2.2e-07</td>\n<td>0.0</td>\n<td>1.1057591</td>\n<td>0.0</td>\n<td>0.0000003</td>\n<td>0.5528796</td>\n<td>0.5529505</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>10.5759134</td>\n<td>0.1912878</td></tr>\n<tr><td>15</td>\n<td>1.0</td>\n<td>1e-08</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.0000001</td>\n<td>0.5</td>\n<td>0.5000641</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-9.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-9 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-9 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-9 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-9 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-9 .h2o-table th,\n#h2o-table-9 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-9 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-9\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>auc</td>\n<td>0.9999977</td>\n<td>0.0000030</td>\n<td>0.999993</td>\n<td>0.9999963</td>\n<td>0.9999992</td>\n<td>0.9999999</td>\n<td>0.9999999</td></tr>\n<tr><td>err</td>\n<td>0.0000106</td>\n<td>0.0000039</td>\n<td>0.0000088</td>\n<td>0.0000176</td>\n<td>0.0000088</td>\n<td>0.0000088</td>\n<td>0.0000088</td></tr>\n<tr><td>err_count</td>\n<td>1.2</td>\n<td>0.4472136</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td></tr>\n<tr><td>f0point5</td>\n<td>0.9999831</td>\n<td>0.0000063</td>\n<td>0.9999859</td>\n<td>0.9999719</td>\n<td>0.9999859</td>\n<td>0.9999859</td>\n<td>0.9999859</td></tr>\n<tr><td>f1</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>f2</td>\n<td>0.9999958</td>\n<td>0.0000016</td>\n<td>0.9999965</td>\n<td>0.9999930</td>\n<td>0.9999965</td>\n<td>0.9999965</td>\n<td>0.9999965</td></tr>\n<tr><td>lift_top_group</td>\n<td>2.0</td>\n<td>0.0003482</td>\n<td>2.0004573</td>\n<td>1.999789</td>\n<td>2.0001056</td>\n<td>2.0001056</td>\n<td>1.9995428</td></tr>\n<tr><td>logloss</td>\n<td>0.0003513</td>\n<td>0.0001510</td>\n<td>0.0004516</td>\n<td>0.0005583</td>\n<td>0.0003089</td>\n<td>0.0002460</td>\n<td>0.0001918</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.0000211</td>\n<td>0.0000079</td>\n<td>0.0000176</td>\n<td>0.0000352</td>\n<td>0.0000176</td>\n<td>0.0000176</td>\n<td>0.0000176</td></tr>\n<tr><td>mcc</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.0000106</td>\n<td>0.0000039</td>\n<td>0.0000088</td>\n<td>0.0000176</td>\n<td>0.0000088</td>\n<td>0.0000088</td>\n<td>0.0000088</td></tr>\n<tr><td>mse</td>\n<td>0.0000517</td>\n<td>0.0000237</td>\n<td>0.0000730</td>\n<td>0.0000726</td>\n<td>0.0000588</td>\n<td>0.0000337</td>\n<td>0.0000205</td></tr>\n<tr><td>pr_auc</td>\n<td>0.9999972</td>\n<td>0.0000038</td>\n<td>0.9999911</td>\n<td>0.9999959</td>\n<td>0.9999992</td>\n<td>0.9999999</td>\n<td>0.9999999</td></tr>\n<tr><td>precision</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr>\n<tr><td>r2</td>\n<td>0.9997931</td>\n<td>0.0000946</td>\n<td>0.9997079</td>\n<td>0.9997095</td>\n<td>0.9997648</td>\n<td>0.9998653</td>\n<td>0.9999179</td></tr>\n<tr><td>recall</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td></tr>\n<tr><td>rmse</td>\n<td>0.0070133</td>\n<td>0.0017806</td>\n<td>0.0085447</td>\n<td>0.0085211</td>\n<td>0.0076680</td>\n<td>0.0058035</td>\n<td>0.0045292</td></tr>\n<tr><td>specificity</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-05-17 07:19:55</td>\n<td>12 min 24.175 sec</td>\n<td>0.0</td>\n<td>0.5</td>\n<td>0.6931472</td>\n<td>0.5</td>\n<td>0.5</td>\n<td>1.0</td>\n<td>0.5</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:00</td>\n<td>12 min 29.378 sec</td>\n<td>5.0</td>\n<td>0.3027539</td>\n<td>0.3602736</td>\n<td>0.9999584</td>\n<td>0.9999550</td>\n<td>2.0</td>\n<td>0.0003658</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:04</td>\n<td>12 min 33.804 sec</td>\n<td>10.0</td>\n<td>0.1846397</td>\n<td>0.2032972</td>\n<td>0.9999719</td>\n<td>0.9999686</td>\n<td>2.0</td>\n<td>0.0001706</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:09</td>\n<td>12 min 38.447 sec</td>\n<td>15.0</td>\n<td>0.1141046</td>\n<td>0.1196577</td>\n<td>0.9999778</td>\n<td>0.9999752</td>\n<td>2.0</td>\n<td>0.0001424</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:13</td>\n<td>12 min 42.894 sec</td>\n<td>20.0</td>\n<td>0.0713811</td>\n<td>0.0718511</td>\n<td>0.9999804</td>\n<td>0.9999777</td>\n<td>2.0</td>\n<td>0.0001126</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:18</td>\n<td>12 min 47.319 sec</td>\n<td>25.0</td>\n<td>0.0460620</td>\n<td>0.0438454</td>\n<td>0.9999806</td>\n<td>0.9999762</td>\n<td>2.0</td>\n<td>0.0001020</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:22</td>\n<td>12 min 51.737 sec</td>\n<td>30.0</td>\n<td>0.0311125</td>\n<td>0.0270536</td>\n<td>0.9999868</td>\n<td>0.9999849</td>\n<td>2.0</td>\n<td>0.0000633</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:27</td>\n<td>12 min 56.207 sec</td>\n<td>35.0</td>\n<td>0.0225426</td>\n<td>0.0169144</td>\n<td>0.9999871</td>\n<td>0.9999851</td>\n<td>2.0</td>\n<td>0.0000563</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:31</td>\n<td>13 min  0.873 sec</td>\n<td>40.0</td>\n<td>0.0176634</td>\n<td>0.0106555</td>\n<td>0.9999898</td>\n<td>0.9999876</td>\n<td>2.0</td>\n<td>0.0000369</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:36</td>\n<td>13 min  5.344 sec</td>\n<td>45.0</td>\n<td>0.0145891</td>\n<td>0.0067959</td>\n<td>0.9999931</td>\n<td>0.9999922</td>\n<td>2.0</td>\n<td>0.0000299</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:40</td>\n<td>14 min  9.354 sec</td>\n<td>120.0</td>\n<td>0.0006531</td>\n<td>0.0000316</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:44</td>\n<td>14 min 13.724 sec</td>\n<td>125.0</td>\n<td>0.0005084</td>\n<td>0.0000238</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:48</td>\n<td>14 min 17.850 sec</td>\n<td>130.0</td>\n<td>0.0003884</td>\n<td>0.0000180</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:52</td>\n<td>14 min 21.987 sec</td>\n<td>135.0</td>\n<td>0.0003074</td>\n<td>0.0000137</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:57</td>\n<td>14 min 26.099 sec</td>\n<td>140.0</td>\n<td>0.0002406</td>\n<td>0.0000105</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:01</td>\n<td>14 min 30.231 sec</td>\n<td>145.0</td>\n<td>0.0001890</td>\n<td>0.0000079</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:05</td>\n<td>14 min 34.370 sec</td>\n<td>150.0</td>\n<td>0.0001446</td>\n<td>0.0000058</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:09</td>\n<td>14 min 38.566 sec</td>\n<td>155.0</td>\n<td>0.0001057</td>\n<td>0.0000042</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:13</td>\n<td>14 min 43.001 sec</td>\n<td>160.0</td>\n<td>0.0000790</td>\n<td>0.0000032</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:16</td>\n<td>14 min 45.568 sec</td>\n<td>163.0</td>\n<td>0.0000709</td>\n<td>0.0000027</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[34 rows x 10 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>V14</td>\n<td>249937.8593750</td>\n<td>1.0</td>\n<td>0.3502173</td></tr>\n<tr><td>V10</td>\n<td>212824.1093750</td>\n<td>0.8515081</td>\n<td>0.2982129</td></tr>\n<tr><td>V11</td>\n<td>77671.3359375</td>\n<td>0.3107626</td>\n<td>0.1088344</td></tr>\n<tr><td>V4</td>\n<td>36254.7187500</td>\n<td>0.1450549</td>\n<td>0.0508008</td></tr>\n<tr><td>V17</td>\n<td>28100.4335938</td>\n<td>0.1124297</td>\n<td>0.0393748</td></tr>\n<tr><td>V12</td>\n<td>12264.8359375</td>\n<td>0.0490715</td>\n<td>0.0171857</td></tr>\n<tr><td>V26</td>\n<td>9074.3583984</td>\n<td>0.0363065</td>\n<td>0.0127152</td></tr>\n<tr><td>V3</td>\n<td>8412.3710938</td>\n<td>0.0336579</td>\n<td>0.0117876</td></tr>\n<tr><td>V13</td>\n<td>8358.1210938</td>\n<td>0.0334408</td>\n<td>0.0117115</td></tr>\n<tr><td>V8</td>\n<td>6165.6772461</td>\n<td>0.0246688</td>\n<td>0.0086395</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>V9</td>\n<td>3120.1035156</td>\n<td>0.0124835</td>\n<td>0.0043719</td></tr>\n<tr><td>V22</td>\n<td>3079.0705566</td>\n<td>0.0123193</td>\n<td>0.0043144</td></tr>\n<tr><td>V23</td>\n<td>2943.3044434</td>\n<td>0.0117761</td>\n<td>0.0041242</td></tr>\n<tr><td>V6</td>\n<td>2751.6120605</td>\n<td>0.0110092</td>\n<td>0.0038556</td></tr>\n<tr><td>V21</td>\n<td>2601.3071289</td>\n<td>0.0104078</td>\n<td>0.0036450</td></tr>\n<tr><td>V5</td>\n<td>2238.6335449</td>\n<td>0.0089568</td>\n<td>0.0031368</td></tr>\n<tr><td>V24</td>\n<td>1781.6501465</td>\n<td>0.0071284</td>\n<td>0.0024965</td></tr>\n<tr><td>V27</td>\n<td>1344.9044189</td>\n<td>0.0053810</td>\n<td>0.0018845</td></tr>\n<tr><td>V28</td>\n<td>1290.6734619</td>\n<td>0.0051640</td>\n<td>0.0018085</td></tr>\n<tr><td>V2</td>\n<td>1205.9401855</td>\n<td>0.0048250</td>\n<td>0.0016898</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[29 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Leader board","metadata":{}},{"cell_type":"code","source":"# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:42:14.307368Z","iopub.execute_input":"2023-05-17T07:42:14.307724Z","iopub.status.idle":"2023-05-17T07:42:14.330758Z","shell.execute_reply.started":"2023-05-17T07:42:14.307694Z","shell.execute_reply":"2023-05-17T07:42:14.329049Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"model_id                                                     auc      logloss     aucpr    mean_per_class_error        rmse          mse\n------------------------------------------------------  --------  -----------  --------  ----------------------  ----------  -----------\nGBM_1_AutoML_2_20230517_63622                           0.999998  0.000347033  0.999998             1.23103e-05  0.00726994  5.2852e-05\nStackedEnsemble_BestOfFamily_1_AutoML_2_20230517_63622  0.999998  0.000362196  0.999997             1.05517e-05  0.00692811  4.79988e-05\nXGBoost_1_AutoML_2_20230517_63622                       0.999994  0.000503743  0.999993             1.58275e-05  0.00940028  8.83653e-05\nGLM_1_AutoML_2_20230517_63622                           0.9859    0.137569     0.988587             0.0502664    0.198522    0.0394111\n[4 rows x 7 columns]\n","text/html":"<table class='dataframe'>\n<thead>\n<tr><th>model_id                                              </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">    logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">      rmse</th><th style=\"text-align: right;\">        mse</th></tr>\n</thead>\n<tbody>\n<tr><td>GBM_1_AutoML_2_20230517_63622                         </td><td style=\"text-align: right;\">0.999998</td><td style=\"text-align: right;\">0.000347033</td><td style=\"text-align: right;\">0.999998</td><td style=\"text-align: right;\">           1.23103e-05</td><td style=\"text-align: right;\">0.00726994</td><td style=\"text-align: right;\">5.2852e-05 </td></tr>\n<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_2_20230517_63622</td><td style=\"text-align: right;\">0.999998</td><td style=\"text-align: right;\">0.000362196</td><td style=\"text-align: right;\">0.999997</td><td style=\"text-align: right;\">           1.05517e-05</td><td style=\"text-align: right;\">0.00692811</td><td style=\"text-align: right;\">4.79988e-05</td></tr>\n<tr><td>XGBoost_1_AutoML_2_20230517_63622                     </td><td style=\"text-align: right;\">0.999994</td><td style=\"text-align: right;\">0.000503743</td><td style=\"text-align: right;\">0.999993</td><td style=\"text-align: right;\">           1.58275e-05</td><td style=\"text-align: right;\">0.00940028</td><td style=\"text-align: right;\">8.83653e-05</td></tr>\n<tr><td>GLM_1_AutoML_2_20230517_63622                         </td><td style=\"text-align: right;\">0.9859  </td><td style=\"text-align: right;\">0.137569   </td><td style=\"text-align: right;\">0.988587</td><td style=\"text-align: right;\">           0.0502664  </td><td style=\"text-align: right;\">0.198522  </td><td style=\"text-align: right;\">0.0394111  </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[4 rows x 7 columns]</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Best Model","metadata":{}},{"cell_type":"code","source":"aml.leader","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:42:18.863069Z","iopub.execute_input":"2023-05-17T07:42:18.863585Z","iopub.status.idle":"2023-05-17T07:42:18.928320Z","shell.execute_reply.started":"2023-05-17T07:42:18.863560Z","shell.execute_reply":"2023-05-17T07:42:18.927246Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_2_20230517_63622\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    163                163                         766771                 15           15           15            108           710           369.485\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 5.022656839270833e-09\nRMSE: 7.087070508518194e-05\nLogLoss: 2.7328193386006475e-06\nMean Per-Class Error: 0.0\nAUC: 1.0\nAUCPR: 1.0\nGini: 1.0\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999251145067237\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284315  0       0        (0.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284315  284315  0        (0.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999925     1         69\nmax f2                       0.999925     1         69\nmax f0point5                 0.999925     1         69\nmax accuracy                 0.999925     1         69\nmax precision                1            1         0\nmax recall                   0.999925     1         69\nmax specificity              1            1         0\nmax absolute_mcc             0.999925     1         69\nmax min_per_class_accuracy   0.999925     1         69\nmax mean_per_class_accuracy  0.999925     1         69\nmax tns                      1            284315    0\nmax fns                      1            248119    0\nmax fps                      1.39826e-07  284315    399\nmax tps                      0.999925     284315    69\nmax tnr                      1            1         0\nmax fnr                      1            0.872691  0\nmax fpr                      1.39826e-07  1         399\nmax tpr                      0.999925     1         69\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.00 %\ngroup    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------  --------------------\n1        0.0103406                   1                  2       2                  1                1            1                           1                   0.0206813       0.0206813                  100     100                0.0206813\n2        0.0203735                   1                  2       2                  1                1            1                           1                   0.0200658       0.0407471                  100     100                0.0407471\n3        0.030176                    1                  2       2                  1                1            1                           1                   0.019605        0.0603521                  100     100                0.0603521\n4        0.0403795                   1                  2       2                  1                1            1                           1                   0.0204069       0.080759                   100     100                0.080759\n5        0.050532                    1                  2       2                  1                1            1                           1                   0.0203049       0.101064                   100     100                0.101064\n6        0.100492                    1                  2       2                  1                1            1                           1                   0.0999209       0.200985                   100     100                0.200985\n7        0.15043                     1                  2       2                  1                1            1                           1                   0.0998751       0.30086                    100     100                0.30086\n8        0.200557                    1                  2       2                  1                1            1                           1                   0.100255        0.401115                   100     100                0.401115\n9        0.300684                    0.999999           2       2                  1                1            1                           1                   0.200253        0.601368                   100     100                0.601368\n10       0.400623                    0.999998           2       2                  1                0.999999     1                           1                   0.199877        0.801245                   100     100                0.801245\n11       0.5                         0.512797           2       2                  1                0.999989     1                           0.999997            0.198755        1                          100     100                1\n12       0.6                         1.26408e-06        0       1.66667            0                1.2205e-05   0.833333                    0.833333            0               1                          -100    66.6667            0.8\n13       0.700002                    8.13358e-07        0       1.42857            0                9.96208e-07  0.714284                    0.714284            0               1                          -100    42.8568            0.599996\n14       0.800004                    6.14536e-07        0       1.24999            0                7.0566e-07   0.624997                    0.624997            0               1                          -100    24.9995            0.399993\n15       0.9                         4.61838e-07        0       1.11111            0                5.38762e-07  0.555556                    0.555556            0               1                          -100    11.1111            0.2\n16       1                           7.6676e-09         0       1                  0                3.54251e-07  0.5                         0.5                 0               1                          -100    0                  0\n\nModelMetricsBinomial: gbm\n** Reported on cross-validation data. **\n\nMSE: 5.28519684336538e-05\nRMSE: 0.007269935930505426\nLogLoss: 0.00034703292888788734\nMean Per-Class Error: 1.2310289643529185e-05\nAUC: 0.9999978008850409\nAUCPR: 0.9999975406058657\nGini: 0.9999956017700817\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9998410272152997\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284308  7       0        (7.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284308  284322  0        (7.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999841     0.999988  66\nmax f2                       0.999841     0.999995  66\nmax f0point5                 0.999841     0.99998   66\nmax accuracy                 0.999841     0.999988  66\nmax precision                1            1         0\nmax recall                   0.999841     1         66\nmax specificity              1            1         0\nmax absolute_mcc             0.999841     0.999975  66\nmax min_per_class_accuracy   0.999841     0.999975  66\nmax mean_per_class_accuracy  0.999841     0.999988  66\nmax tns                      1            284315    0\nmax fns                      1            202390    0\nmax fps                      1.42627e-07  284315    399\nmax tps                      0.999841     284315    66\nmax tnr                      1            1         0\nmax fnr                      1            0.711851  0\nmax fpr                      1.42627e-07  1         399\nmax tpr                      0.999841     1         66\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.01 %\ngroup    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n1        0.0115365                   1                  2        2                  1                1            1                           1                   0.023073        0.023073                   100      100                0.023073\n2        0.0239752                   1                  2        2                  1                1            1                           1                   0.0248773       0.0479503                  100      100                0.0479503\n3        0.0395952                   1                  2        2                  1                1            1                           1                   0.03124         0.0791903                  100      100                0.0791903\n4        0.0531945                   1                  2        2                  1                1            1                           1                   0.0271987       0.106389                   100      100                0.106389\n5        0.104474                    1                  2        2                  1                1            1                           1                   0.102559        0.208948                   100      100                0.208948\n6        0.151923                    1                  2        2                  1                1            1                           1                   0.0948983       0.303846                   100      100                0.303846\n7        0.202161                    1                  2        2                  1                1            1                           1                   0.100477        0.404323                   100      100                0.404323\n8        0.300918                    0.999999           2        2                  1                0.999999     1                           1                   0.197513        0.601836                   100      100                0.601836\n9        0.400067                    0.999998           1.99996  1.99999            0.999982         0.999999     0.999996                    0.999999            0.198294        0.80013                    99.9965  99.9991            0.800127\n10       0.500012                    0.999841           1.99979  1.99995            0.999894         0.999987     0.999975                    0.999997            0.19987         1                          99.9789  99.9951            0.999975\n11       0.600353                    1.87e-06           0        1.66569            0                0.000529523  0.832843                    0.832949            0               1                          -100     66.5685            0.799293\n12       0.700257                    1.02e-06           0        1.42805            0                1.42028e-06  0.714024                    0.714115            0               1                          -100     42.8048            0.599486\n13       0.803433                    4e-07              0        1.24466            0                6.43974e-07  0.62233                     0.622409            0               1                          -100     24.4659            0.393134\n14       0.904356                    2.2e-07            0        1.10576            0                2.9427e-07   0.55288                     0.55295             0               1                          -100     10.5759            0.191288\n15       1                           1e-08              0        1                  0                1.48704e-07  0.5                         0.500064            0               1                          -100     0                  0\n\nCross-Validation Metrics Summary: \n                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.999989     3.93238e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nauc                      0.999998     3.0045e-06   0.999993      0.999996      0.999999      1             1\nerr                      1.05517e-05  3.93238e-06  8.79306e-06   1.75861e-05   8.79306e-06   8.79306e-06   8.79306e-06\nerr_count                1.2          0.447214     1             2             1             1             1\nf0point5                 0.999983     6.29007e-06  0.999986      0.999972      0.999986      0.999986      0.999986\nf1                       0.999989     3.93131e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nf2                       0.999996     1.57248e-06  0.999996      0.999993      0.999996      0.999996      0.999996\nlift_top_group           2            0.000348185  2.00046       1.99979       2.00011       2.00011       1.99954\nlogloss                  0.000351323  0.000151033  0.000451642   0.000558287   0.000308915   0.00024597    0.000191799\nmax_per_class_error      2.11037e-05  7.86662e-06  1.75821e-05   3.5176e-05    1.75852e-05   1.75852e-05   1.75901e-05\nmcc                      0.999979     7.86452e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nmean_per_class_accuracy  0.999989     3.93329e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nmean_per_class_error     1.05519e-05  3.93331e-06  8.79105e-06   1.7588e-05    8.7926e-06    8.7926e-06    8.79507e-06\nmse                      5.17228e-05  2.36595e-05  7.30121e-05   7.26092e-05   5.87986e-05   3.36802e-05   2.05139e-05\npr_auc                   0.999997     3.80841e-06  0.999991      0.999996      0.999999      1             1\nprecision                0.999979     7.86249e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nr2                       0.999793     9.46379e-05  0.999708      0.99971       0.999765      0.999865      0.999918\nrecall                   1            0            1             1             1             1             1\nrmse                     0.0070133    0.00178057   0.00854471    0.00852111    0.00766802    0.00580346    0.00452922\nspecificity              0.999979     7.86664e-06  0.999982      0.999965      0.999982      0.999982      0.999982\n\nScoring History: \n     timestamp            duration           number_of_trees    training_rmse           training_logloss        training_auc        training_pr_auc     training_lift    training_classification_error\n---  -------------------  -----------------  -----------------  ----------------------  ----------------------  ------------------  ------------------  ---------------  -------------------------------\n     2023-05-17 07:19:55  12 min 24.175 sec  0.0                0.5                     0.6931471805594906      0.5                 0.5                 1.0              0.5\n     2023-05-17 07:20:00  12 min 29.378 sec  5.0                0.3027539076569943      0.3602735758590258      0.9999583736599278  0.9999549519021839  2.0              0.0003657914636934386\n     2023-05-17 07:20:04  12 min 33.804 sec  10.0               0.18463969334455507     0.20329722217602272     0.9999718745969037  0.9999686281391038  2.0              0.00017058544220319012\n     2023-05-17 07:20:09  12 min 38.447 sec  15.0               0.11410464082101325     0.11965766447485039     0.9999777823025563  0.9999752353590851  2.0              0.00014244763730369484\n     2023-05-17 07:20:13  12 min 42.894 sec  20.0               0.07138108330623394     0.07185105158083227     0.999980356446807   0.9999776805877443  2.0              0.00011255121959798112\n     2023-05-17 07:20:18  12 min 47.319 sec  25.0               0.046061955280494817    0.043845401522722725    0.9999806441006015  0.999976224745567   2.0              0.00010199954276067039\n     2023-05-17 07:20:22  12 min 51.737 sec  30.0               0.031112452481983334    0.027053597850049866    0.9999868172790677  0.9999849079339339  2.0              6.331006102386438e-05\n     2023-05-17 07:20:27  12 min 56.207 sec  35.0               0.022542550826428295    0.016914393938143465    0.9999870962361362  0.9999850721470551  2.0              5.627560979899056e-05\n     2023-05-17 07:20:31  13 min  0.873 sec  40.0               0.01766341943799046     0.010655517859075214    0.9999898275585523  0.9999876122116917  2.0              3.693086893058755e-05\n     2023-05-17 07:20:36  13 min  5.344 sec  45.0               0.014589120101518471    0.006795877655729194    0.9999930655673077  0.9999921776834312  2.0              2.9896417705713734e-05\n---  ---                  ---                ---                ---                     ---                     ---                 ---                 ---              ---\n     2023-05-17 07:21:40  14 min  9.354 sec  120.0              0.00065306377424895     3.16432556309842e-05    1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:44  14 min 13.724 sec  125.0              0.0005084018965388476   2.3808421309119888e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:48  14 min 17.850 sec  130.0              0.00038844359738230647  1.7968339872344618e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:52  14 min 21.987 sec  135.0              0.0003073750563567389   1.3719138034083516e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:57  14 min 26.099 sec  140.0              0.0002405969824860052   1.0488524185782484e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:01  14 min 30.231 sec  145.0              0.00018904533995990288  7.854240501567559e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:05  14 min 34.370 sec  150.0              0.00014462769065615446  5.797557939228732e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:09  14 min 38.566 sec  155.0              0.00010567787499643689  4.2219134693428804e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:13  14 min 43.001 sec  160.0              7.900020814711673e-05   3.1864422688417992e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:16  14 min 45.568 sec  163.0              7.087070508518194e-05   2.7328193386006475e-06  1.0                 1.0                 2.0              0.0\n[34 rows x 10 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance      percentage\n----------  ---------------------  ---------------------  ---------------------\nV14         249937.859375          1.0                    0.35021734738652266\nV10         212824.109375          0.8515080904797399     0.2982129047259776\nV11         77671.3359375          0.31076258767569914    0.10883444912275503\nV4          36254.71875            0.14505493021609184    0.050800752885616834\nV17         28100.43359375         0.11242968017737909    0.03937482435923682\nV12         12264.8359375          0.04907154109493341    0.017185704954436318\nV26         9074.3583984375        0.03630645801772103    0.012715151419966406\nV3          8412.37109375          0.03365785045445358    0.011787563104891001\nV13         8358.12109375          0.03344079650298077    0.01171154704576643\nV8          6165.67724609375       0.02466884073309972    0.008639455964646785\n---         ---                    ---                    ---\nV9          3120.103515625         0.01248351699669349    0.004371944208636565\nV22         3079.070556640625      0.01231934435359339    0.004314448101056613\nV23         2943.304443359375      0.011776144881449596   0.004124210222820654\nV6          2751.612060546875      0.01100918471266264    0.003855607466956967\nV21         2601.30712890625       0.010407815508267273   0.003644997539393678\nV5          2238.633544921875      0.008956760494467907   0.0031368129015489493\nV24         1781.650146484375      0.007128372432010132   0.0024964796843218034\nV27         1344.9044189453125     0.0053809551794530425  0.0018845038493538148\nV28         1290.6734619140625     0.005163977418793409   0.00180851447357373\nV2          1205.940185546875      0.004824960046319013   0.0016897847086677982\n[29 rows x 4 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_2_20230517_63622\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th>\n<th>number_of_internal_trees</th>\n<th>model_size_in_bytes</th>\n<th>min_depth</th>\n<th>max_depth</th>\n<th>mean_depth</th>\n<th>min_leaves</th>\n<th>max_leaves</th>\n<th>mean_leaves</th></tr></thead>\n    <tbody><tr><td></td>\n<td>163.0</td>\n<td>163.0</td>\n<td>766771.0</td>\n<td>15.0</td>\n<td>15.0</td>\n<td>15.0</td>\n<td>108.0</td>\n<td>710.0</td>\n<td>369.48465</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 5.022656839270833e-09\nRMSE: 7.087070508518194e-05\nLogLoss: 2.7328193386006475e-06\nMean Per-Class Error: 0.0\nAUC: 1.0\nAUCPR: 1.0\nGini: 1.0</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999251145067237</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>1</td>\n<td>0.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>Total</td>\n<td>284315.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/568630.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max f2</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9999999</td>\n<td>284315.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9999999</td>\n<td>248119.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0000001</td>\n<td>284315.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.9999251</td>\n<td>284315.0</td>\n<td>69.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9999999</td>\n<td>0.8726905</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0000001</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.9999251</td>\n<td>1.0</td>\n<td>69.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.00 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0103406</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0206813</td>\n<td>0.0206813</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0206813</td></tr>\n<tr><td>2</td>\n<td>0.0203735</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0200658</td>\n<td>0.0407471</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0407471</td></tr>\n<tr><td>3</td>\n<td>0.0301760</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0196050</td>\n<td>0.0603521</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0603521</td></tr>\n<tr><td>4</td>\n<td>0.0403795</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0204069</td>\n<td>0.0807590</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0807590</td></tr>\n<tr><td>5</td>\n<td>0.0505320</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0203049</td>\n<td>0.1010640</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.1010640</td></tr>\n<tr><td>6</td>\n<td>0.1004924</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0999209</td>\n<td>0.2009848</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.2009848</td></tr>\n<tr><td>7</td>\n<td>0.1504300</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>0.0998751</td>\n<td>0.3008600</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.3008600</td></tr>\n<tr><td>8</td>\n<td>0.2005575</td>\n<td>0.9999997</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>0.1002550</td>\n<td>0.4011150</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.4011150</td></tr>\n<tr><td>9</td>\n<td>0.3006841</td>\n<td>0.9999994</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999996</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>0.2002532</td>\n<td>0.6013682</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.6013682</td></tr>\n<tr><td>10</td>\n<td>0.4006225</td>\n<td>0.9999978</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999988</td>\n<td>1.0</td>\n<td>0.9999995</td>\n<td>0.1998769</td>\n<td>0.8012451</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.8012451</td></tr>\n<tr><td>11</td>\n<td>0.5</td>\n<td>0.5127973</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999894</td>\n<td>1.0</td>\n<td>0.9999975</td>\n<td>0.1987549</td>\n<td>1.0</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>1.0</td></tr>\n<tr><td>12</td>\n<td>0.6</td>\n<td>0.0000013</td>\n<td>0.0</td>\n<td>1.6666667</td>\n<td>0.0</td>\n<td>0.0000122</td>\n<td>0.8333333</td>\n<td>0.8333333</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>66.6666667</td>\n<td>0.8</td></tr>\n<tr><td>13</td>\n<td>0.7000018</td>\n<td>0.0000008</td>\n<td>0.0</td>\n<td>1.4285678</td>\n<td>0.0</td>\n<td>0.0000010</td>\n<td>0.7142839</td>\n<td>0.7142840</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>42.8567840</td>\n<td>0.5999965</td></tr>\n<tr><td>14</td>\n<td>0.8000035</td>\n<td>0.0000006</td>\n<td>0.0</td>\n<td>1.2499945</td>\n<td>0.0</td>\n<td>0.0000007</td>\n<td>0.6249973</td>\n<td>0.6249974</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>24.9994504</td>\n<td>0.3999930</td></tr>\n<tr><td>15</td>\n<td>0.9</td>\n<td>0.0000005</td>\n<td>0.0</td>\n<td>1.1111111</td>\n<td>0.0</td>\n<td>0.0000005</td>\n<td>0.5555556</td>\n<td>0.5555558</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>11.1111111</td>\n<td>0.2000000</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0000000</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.0000004</td>\n<td>0.5</td>\n<td>0.5000002</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on cross-validation data. **\n\nMSE: 5.28519684336538e-05\nRMSE: 0.007269935930505426\nLogLoss: 0.00034703292888788734\nMean Per-Class Error: 1.2310289643529185e-05\nAUC: 0.9999978008850409\nAUCPR: 0.9999975406058657\nGini: 0.9999956017700817</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9998410272152997</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>284308.0</td>\n<td>7.0</td>\n<td>0.0</td>\n<td> (7.0/284315.0)</td></tr>\n<tr><td>1</td>\n<td>0.0</td>\n<td>284315.0</td>\n<td>0.0</td>\n<td> (0.0/284315.0)</td></tr>\n<tr><td>Total</td>\n<td>284308.0</td>\n<td>284322.0</td>\n<td>0.0</td>\n<td> (7.0/568630.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max f2</td>\n<td>0.9998410</td>\n<td>0.9999951</td>\n<td>66.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.9998410</td>\n<td>0.9999803</td>\n<td>66.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.9998410</td>\n<td>1.0</td>\n<td>66.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.9998410</td>\n<td>0.9999754</td>\n<td>66.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.9998410</td>\n<td>0.9999754</td>\n<td>66.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.9998410</td>\n<td>0.9999877</td>\n<td>66.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9999999</td>\n<td>284315.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9999999</td>\n<td>202390.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0000001</td>\n<td>284315.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.9998410</td>\n<td>284315.0</td>\n<td>66.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9999999</td>\n<td>0.7118513</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0000001</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.9998410</td>\n<td>1.0</td>\n<td>66.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-18.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-18 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-18 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-18 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-18 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-18 .h2o-table th,\n#h2o-table-18 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-18 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-18\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 50.00 %, avg score: 50.01 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0115365</td>\n<td>1.0000000</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0230730</td>\n<td>0.0230730</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0230730</td></tr>\n<tr><td>2</td>\n<td>0.0239752</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0248773</td>\n<td>0.0479503</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0479503</td></tr>\n<tr><td>3</td>\n<td>0.0395952</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>1.0000000</td>\n<td>0.0312400</td>\n<td>0.0791903</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.0791903</td></tr>\n<tr><td>4</td>\n<td>0.0531945</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0271987</td>\n<td>0.1063890</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.1063890</td></tr>\n<tr><td>5</td>\n<td>0.1044739</td>\n<td>0.9999999</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.1025588</td>\n<td>0.2089478</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.2089478</td></tr>\n<tr><td>6</td>\n<td>0.1519230</td>\n<td>0.9999998</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999998</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.0948983</td>\n<td>0.3038461</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.3038461</td></tr>\n<tr><td>7</td>\n<td>0.2021613</td>\n<td>0.9999996</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>1.0</td>\n<td>0.9999999</td>\n<td>0.1004766</td>\n<td>0.4043227</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.4043227</td></tr>\n<tr><td>8</td>\n<td>0.3009180</td>\n<td>0.9999992</td>\n<td>2.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>0.9999994</td>\n<td>1.0</td>\n<td>0.9999997</td>\n<td>0.1975133</td>\n<td>0.6018360</td>\n<td>100.0</td>\n<td>100.0</td>\n<td>0.6018360</td></tr>\n<tr><td>9</td>\n<td>0.4000668</td>\n<td>0.9999976</td>\n<td>1.9999645</td>\n<td>1.9999912</td>\n<td>0.9999823</td>\n<td>0.9999986</td>\n<td>0.9999956</td>\n<td>0.9999994</td>\n<td>0.1982941</td>\n<td>0.8001301</td>\n<td>99.9964526</td>\n<td>99.9991208</td>\n<td>0.8001266</td></tr>\n<tr><td>10</td>\n<td>0.5000123</td>\n<td>0.9998410</td>\n<td>1.9997889</td>\n<td>1.9999508</td>\n<td>0.9998944</td>\n<td>0.9999867</td>\n<td>0.9999754</td>\n<td>0.9999969</td>\n<td>0.1998699</td>\n<td>1.0</td>\n<td>99.9788851</td>\n<td>99.9950760</td>\n<td>0.9999754</td></tr>\n<tr><td>11</td>\n<td>0.6003535</td>\n<td>1.87e-06</td>\n<td>0.0</td>\n<td>1.6656854</td>\n<td>0.0</td>\n<td>0.0005295</td>\n<td>0.8328427</td>\n<td>0.8329491</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>66.5685353</td>\n<td>0.7992930</td></tr>\n<tr><td>12</td>\n<td>0.7002568</td>\n<td>1.02e-06</td>\n<td>0.0</td>\n<td>1.4280476</td>\n<td>0.0</td>\n<td>0.0000014</td>\n<td>0.7140238</td>\n<td>0.7141153</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>42.8047626</td>\n<td>0.5994865</td></tr>\n<tr><td>13</td>\n<td>0.8034328</td>\n<td>4e-07</td>\n<td>0.0</td>\n<td>1.2446591</td>\n<td>0.0</td>\n<td>0.0000006</td>\n<td>0.6223296</td>\n<td>0.6224094</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>24.4659149</td>\n<td>0.3931344</td></tr>\n<tr><td>14</td>\n<td>0.9043561</td>\n<td>2.2e-07</td>\n<td>0.0</td>\n<td>1.1057591</td>\n<td>0.0</td>\n<td>0.0000003</td>\n<td>0.5528796</td>\n<td>0.5529505</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>10.5759134</td>\n<td>0.1912878</td></tr>\n<tr><td>15</td>\n<td>1.0</td>\n<td>1e-08</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.0000001</td>\n<td>0.5</td>\n<td>0.5000641</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-19.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-19 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-19 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-19 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-19 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-19 .h2o-table th,\n#h2o-table-19 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-19 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-19\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>auc</td>\n<td>0.9999977</td>\n<td>0.0000030</td>\n<td>0.999993</td>\n<td>0.9999963</td>\n<td>0.9999992</td>\n<td>0.9999999</td>\n<td>0.9999999</td></tr>\n<tr><td>err</td>\n<td>0.0000106</td>\n<td>0.0000039</td>\n<td>0.0000088</td>\n<td>0.0000176</td>\n<td>0.0000088</td>\n<td>0.0000088</td>\n<td>0.0000088</td></tr>\n<tr><td>err_count</td>\n<td>1.2</td>\n<td>0.4472136</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td></tr>\n<tr><td>f0point5</td>\n<td>0.9999831</td>\n<td>0.0000063</td>\n<td>0.9999859</td>\n<td>0.9999719</td>\n<td>0.9999859</td>\n<td>0.9999859</td>\n<td>0.9999859</td></tr>\n<tr><td>f1</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>f2</td>\n<td>0.9999958</td>\n<td>0.0000016</td>\n<td>0.9999965</td>\n<td>0.9999930</td>\n<td>0.9999965</td>\n<td>0.9999965</td>\n<td>0.9999965</td></tr>\n<tr><td>lift_top_group</td>\n<td>2.0</td>\n<td>0.0003482</td>\n<td>2.0004573</td>\n<td>1.999789</td>\n<td>2.0001056</td>\n<td>2.0001056</td>\n<td>1.9995428</td></tr>\n<tr><td>logloss</td>\n<td>0.0003513</td>\n<td>0.0001510</td>\n<td>0.0004516</td>\n<td>0.0005583</td>\n<td>0.0003089</td>\n<td>0.0002460</td>\n<td>0.0001918</td></tr>\n<tr><td>max_per_class_error</td>\n<td>0.0000211</td>\n<td>0.0000079</td>\n<td>0.0000176</td>\n<td>0.0000352</td>\n<td>0.0000176</td>\n<td>0.0000176</td>\n<td>0.0000176</td></tr>\n<tr><td>mcc</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr>\n<tr><td>mean_per_class_accuracy</td>\n<td>0.9999894</td>\n<td>0.0000039</td>\n<td>0.9999912</td>\n<td>0.9999824</td>\n<td>0.9999912</td>\n<td>0.9999912</td>\n<td>0.9999912</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.0000106</td>\n<td>0.0000039</td>\n<td>0.0000088</td>\n<td>0.0000176</td>\n<td>0.0000088</td>\n<td>0.0000088</td>\n<td>0.0000088</td></tr>\n<tr><td>mse</td>\n<td>0.0000517</td>\n<td>0.0000237</td>\n<td>0.0000730</td>\n<td>0.0000726</td>\n<td>0.0000588</td>\n<td>0.0000337</td>\n<td>0.0000205</td></tr>\n<tr><td>pr_auc</td>\n<td>0.9999972</td>\n<td>0.0000038</td>\n<td>0.9999911</td>\n<td>0.9999959</td>\n<td>0.9999992</td>\n<td>0.9999999</td>\n<td>0.9999999</td></tr>\n<tr><td>precision</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr>\n<tr><td>r2</td>\n<td>0.9997931</td>\n<td>0.0000946</td>\n<td>0.9997079</td>\n<td>0.9997095</td>\n<td>0.9997648</td>\n<td>0.9998653</td>\n<td>0.9999179</td></tr>\n<tr><td>recall</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>1.0</td></tr>\n<tr><td>rmse</td>\n<td>0.0070133</td>\n<td>0.0017806</td>\n<td>0.0085447</td>\n<td>0.0085211</td>\n<td>0.0076680</td>\n<td>0.0058035</td>\n<td>0.0045292</td></tr>\n<tr><td>specificity</td>\n<td>0.9999789</td>\n<td>0.0000079</td>\n<td>0.9999824</td>\n<td>0.9999648</td>\n<td>0.9999824</td>\n<td>0.9999824</td>\n<td>0.9999824</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-20.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-20 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-20 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-20 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-20 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-20 .h2o-table th,\n#h2o-table-20 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-20 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-20\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2023-05-17 07:19:55</td>\n<td>12 min 24.175 sec</td>\n<td>0.0</td>\n<td>0.5</td>\n<td>0.6931472</td>\n<td>0.5</td>\n<td>0.5</td>\n<td>1.0</td>\n<td>0.5</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:00</td>\n<td>12 min 29.378 sec</td>\n<td>5.0</td>\n<td>0.3027539</td>\n<td>0.3602736</td>\n<td>0.9999584</td>\n<td>0.9999550</td>\n<td>2.0</td>\n<td>0.0003658</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:04</td>\n<td>12 min 33.804 sec</td>\n<td>10.0</td>\n<td>0.1846397</td>\n<td>0.2032972</td>\n<td>0.9999719</td>\n<td>0.9999686</td>\n<td>2.0</td>\n<td>0.0001706</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:09</td>\n<td>12 min 38.447 sec</td>\n<td>15.0</td>\n<td>0.1141046</td>\n<td>0.1196577</td>\n<td>0.9999778</td>\n<td>0.9999752</td>\n<td>2.0</td>\n<td>0.0001424</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:13</td>\n<td>12 min 42.894 sec</td>\n<td>20.0</td>\n<td>0.0713811</td>\n<td>0.0718511</td>\n<td>0.9999804</td>\n<td>0.9999777</td>\n<td>2.0</td>\n<td>0.0001126</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:18</td>\n<td>12 min 47.319 sec</td>\n<td>25.0</td>\n<td>0.0460620</td>\n<td>0.0438454</td>\n<td>0.9999806</td>\n<td>0.9999762</td>\n<td>2.0</td>\n<td>0.0001020</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:22</td>\n<td>12 min 51.737 sec</td>\n<td>30.0</td>\n<td>0.0311125</td>\n<td>0.0270536</td>\n<td>0.9999868</td>\n<td>0.9999849</td>\n<td>2.0</td>\n<td>0.0000633</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:27</td>\n<td>12 min 56.207 sec</td>\n<td>35.0</td>\n<td>0.0225426</td>\n<td>0.0169144</td>\n<td>0.9999871</td>\n<td>0.9999851</td>\n<td>2.0</td>\n<td>0.0000563</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:31</td>\n<td>13 min  0.873 sec</td>\n<td>40.0</td>\n<td>0.0176634</td>\n<td>0.0106555</td>\n<td>0.9999898</td>\n<td>0.9999876</td>\n<td>2.0</td>\n<td>0.0000369</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:20:36</td>\n<td>13 min  5.344 sec</td>\n<td>45.0</td>\n<td>0.0145891</td>\n<td>0.0067959</td>\n<td>0.9999931</td>\n<td>0.9999922</td>\n<td>2.0</td>\n<td>0.0000299</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:40</td>\n<td>14 min  9.354 sec</td>\n<td>120.0</td>\n<td>0.0006531</td>\n<td>0.0000316</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:44</td>\n<td>14 min 13.724 sec</td>\n<td>125.0</td>\n<td>0.0005084</td>\n<td>0.0000238</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:48</td>\n<td>14 min 17.850 sec</td>\n<td>130.0</td>\n<td>0.0003884</td>\n<td>0.0000180</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:52</td>\n<td>14 min 21.987 sec</td>\n<td>135.0</td>\n<td>0.0003074</td>\n<td>0.0000137</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:21:57</td>\n<td>14 min 26.099 sec</td>\n<td>140.0</td>\n<td>0.0002406</td>\n<td>0.0000105</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:01</td>\n<td>14 min 30.231 sec</td>\n<td>145.0</td>\n<td>0.0001890</td>\n<td>0.0000079</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:05</td>\n<td>14 min 34.370 sec</td>\n<td>150.0</td>\n<td>0.0001446</td>\n<td>0.0000058</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:09</td>\n<td>14 min 38.566 sec</td>\n<td>155.0</td>\n<td>0.0001057</td>\n<td>0.0000042</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:13</td>\n<td>14 min 43.001 sec</td>\n<td>160.0</td>\n<td>0.0000790</td>\n<td>0.0000032</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr>\n<tr><td></td>\n<td>2023-05-17 07:22:16</td>\n<td>14 min 45.568 sec</td>\n<td>163.0</td>\n<td>0.0000709</td>\n<td>0.0000027</td>\n<td>1.0</td>\n<td>1.0</td>\n<td>2.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[34 rows x 10 columns]</pre></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-21.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-21 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-21 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-21 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-21 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-21 .h2o-table th,\n#h2o-table-21 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-21 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-21\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>V14</td>\n<td>249937.8593750</td>\n<td>1.0</td>\n<td>0.3502173</td></tr>\n<tr><td>V10</td>\n<td>212824.1093750</td>\n<td>0.8515081</td>\n<td>0.2982129</td></tr>\n<tr><td>V11</td>\n<td>77671.3359375</td>\n<td>0.3107626</td>\n<td>0.1088344</td></tr>\n<tr><td>V4</td>\n<td>36254.7187500</td>\n<td>0.1450549</td>\n<td>0.0508008</td></tr>\n<tr><td>V17</td>\n<td>28100.4335938</td>\n<td>0.1124297</td>\n<td>0.0393748</td></tr>\n<tr><td>V12</td>\n<td>12264.8359375</td>\n<td>0.0490715</td>\n<td>0.0171857</td></tr>\n<tr><td>V26</td>\n<td>9074.3583984</td>\n<td>0.0363065</td>\n<td>0.0127152</td></tr>\n<tr><td>V3</td>\n<td>8412.3710938</td>\n<td>0.0336579</td>\n<td>0.0117876</td></tr>\n<tr><td>V13</td>\n<td>8358.1210938</td>\n<td>0.0334408</td>\n<td>0.0117115</td></tr>\n<tr><td>V8</td>\n<td>6165.6772461</td>\n<td>0.0246688</td>\n<td>0.0086395</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>V9</td>\n<td>3120.1035156</td>\n<td>0.0124835</td>\n<td>0.0043719</td></tr>\n<tr><td>V22</td>\n<td>3079.0705566</td>\n<td>0.0123193</td>\n<td>0.0043144</td></tr>\n<tr><td>V23</td>\n<td>2943.3044434</td>\n<td>0.0117761</td>\n<td>0.0041242</td></tr>\n<tr><td>V6</td>\n<td>2751.6120605</td>\n<td>0.0110092</td>\n<td>0.0038556</td></tr>\n<tr><td>V21</td>\n<td>2601.3071289</td>\n<td>0.0104078</td>\n<td>0.0036450</td></tr>\n<tr><td>V5</td>\n<td>2238.6335449</td>\n<td>0.0089568</td>\n<td>0.0031368</td></tr>\n<tr><td>V24</td>\n<td>1781.6501465</td>\n<td>0.0071284</td>\n<td>0.0024965</td></tr>\n<tr><td>V27</td>\n<td>1344.9044189</td>\n<td>0.0053810</td>\n<td>0.0018845</td></tr>\n<tr><td>V28</td>\n<td>1290.6734619</td>\n<td>0.0051640</td>\n<td>0.0018085</td></tr>\n<tr><td>V2</td>\n<td>1205.9401855</td>\n<td>0.0048250</td>\n<td>0.0016898</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[29 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"# To generate predictions on a test set, you can make predictions\n# directly on the `H2OAutoML` object or on the leader model\n# object directly\n# preds = aml.predict(test)\n\n# or on leader model:\npreds = aml.leader.predict(test)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:42:29.991445Z","iopub.execute_input":"2023-05-17T07:42:29.991826Z","iopub.status.idle":"2023-05-17T07:42:32.739050Z","shell.execute_reply.started":"2023-05-17T07:42:29.991796Z","shell.execute_reply":"2023-05-17T07:42:32.738149Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"}]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:43:01.507174Z","iopub.execute_input":"2023-05-17T07:43:01.507555Z","iopub.status.idle":"2023-05-17T07:43:01.514407Z","shell.execute_reply.started":"2023-05-17T07:43:01.507522Z","shell.execute_reply":"2023-05-17T07:43:01.513622Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  predict        p0           p1\n---------  --------  -----------\n        0  1         3.87331e-07\n        0  0.999999  7.42735e-07\n        0  0.999995  4.5036e-06\n        0  0.999999  9.3066e-07\n        0  1         2.18236e-07\n        0  0.999999  1.09348e-06\n        0  0.999999  5.15381e-07\n        0  1         3.33872e-07\n        0  0.999999  1.47252e-06\n        0  1         2.52142e-07\n[112384 rows x 3 columns]\n","text/html":"<table class='dataframe'>\n<thead>\n<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">         p1</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">3.87331e-07</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">7.42735e-07</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999995</td><td style=\"text-align: right;\">4.5036e-06 </td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">9.3066e-07 </td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">2.18236e-07</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">1.09348e-06</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">5.15381e-07</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">3.33872e-07</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">1.47252e-06</td></tr>\n<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">2.52142e-07</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[112384 rows x 3 columns]</pre>"},"metadata":{}}]},{"cell_type":"code","source":"dfpd = preds.as_data_frame()\n\ndfpd.to_csv('prediction-outputs.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:49:02.678716Z","iopub.execute_input":"2023-05-17T07:49:02.679109Z","iopub.status.idle":"2023-05-17T07:49:03.277529Z","shell.execute_reply.started":"2023-05-17T07:49:02.679076Z","shell.execute_reply":"2023-05-17T07:49:03.276546Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# save the model\nmodel_path = h2o.save_model(model=aml.leader, path=\"/tmp/mymodel\", force=True)\nprint(model_path)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T08:17:05.135672Z","iopub.execute_input":"2023-05-17T08:17:05.136024Z","iopub.status.idle":"2023-05-17T08:17:05.208617Z","shell.execute_reply.started":"2023-05-17T08:17:05.135982Z","shell.execute_reply":"2023-05-17T08:17:05.207716Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"/tmp/mymodel/GBM_1_AutoML_2_20230517_63622\n","output_type":"stream"}]},{"cell_type":"code","source":"# load the model\nsaved_model = h2o.load_model(model_path)\nprint(saved_model)\n# download the model built above to your local machine\nmy_local_model = h2o.download_model(aml.leader)\nmy_local_model","metadata":{"execution":{"iopub.status.busy":"2023-05-17T08:19:17.512926Z","iopub.execute_input":"2023-05-17T08:19:17.513262Z","iopub.status.idle":"2023-05-17T08:19:17.655518Z","shell.execute_reply.started":"2023-05-17T08:19:17.513239Z","shell.execute_reply":"2023-05-17T08:19:17.654521Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_2_20230517_63622\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    163                163                         766771                 15           15           15            108           710           369.485\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 5.022656839270833e-09\nRMSE: 7.087070508518194e-05\nLogLoss: 2.7328193386006475e-06\nMean Per-Class Error: 0.0\nAUC: 1.0\nAUCPR: 1.0\nGini: 1.0\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999251145067237\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284315  0       0        (0.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284315  284315  0        (0.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999925     1         69\nmax f2                       0.999925     1         69\nmax f0point5                 0.999925     1         69\nmax accuracy                 0.999925     1         69\nmax precision                1            1         0\nmax recall                   0.999925     1         69\nmax specificity              1            1         0\nmax absolute_mcc             0.999925     1         69\nmax min_per_class_accuracy   0.999925     1         69\nmax mean_per_class_accuracy  0.999925     1         69\nmax tns                      1            284315    0\nmax fns                      1            248119    0\nmax fps                      1.39826e-07  284315    399\nmax tps                      0.999925     284315    69\nmax tnr                      1            1         0\nmax fnr                      1            0.872691  0\nmax fpr                      1.39826e-07  1         399\nmax tpr                      0.999925     1         69\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.00 %\ngroup    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain    cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  ------  -----------------  --------------------\n1        0.0103406                   1                  2       2                  1                1            1                           1                   0.0206813       0.0206813                  100     100                0.0206813\n2        0.0203735                   1                  2       2                  1                1            1                           1                   0.0200658       0.0407471                  100     100                0.0407471\n3        0.030176                    1                  2       2                  1                1            1                           1                   0.019605        0.0603521                  100     100                0.0603521\n4        0.0403795                   1                  2       2                  1                1            1                           1                   0.0204069       0.080759                   100     100                0.080759\n5        0.050532                    1                  2       2                  1                1            1                           1                   0.0203049       0.101064                   100     100                0.101064\n6        0.100492                    1                  2       2                  1                1            1                           1                   0.0999209       0.200985                   100     100                0.200985\n7        0.15043                     1                  2       2                  1                1            1                           1                   0.0998751       0.30086                    100     100                0.30086\n8        0.200557                    1                  2       2                  1                1            1                           1                   0.100255        0.401115                   100     100                0.401115\n9        0.300684                    0.999999           2       2                  1                1            1                           1                   0.200253        0.601368                   100     100                0.601368\n10       0.400623                    0.999998           2       2                  1                0.999999     1                           1                   0.199877        0.801245                   100     100                0.801245\n11       0.5                         0.512797           2       2                  1                0.999989     1                           0.999997            0.198755        1                          100     100                1\n12       0.6                         1.26408e-06        0       1.66667            0                1.2205e-05   0.833333                    0.833333            0               1                          -100    66.6667            0.8\n13       0.700002                    8.13358e-07        0       1.42857            0                9.96208e-07  0.714284                    0.714284            0               1                          -100    42.8568            0.599996\n14       0.800004                    6.14536e-07        0       1.24999            0                7.0566e-07   0.624997                    0.624997            0               1                          -100    24.9995            0.399993\n15       0.9                         4.61838e-07        0       1.11111            0                5.38762e-07  0.555556                    0.555556            0               1                          -100    11.1111            0.2\n16       1                           7.6676e-09         0       1                  0                3.54251e-07  0.5                         0.5                 0               1                          -100    0                  0\n\nModelMetricsBinomial: gbm\n** Reported on cross-validation data. **\n\nMSE: 5.28519684336538e-05\nRMSE: 0.007269935930505426\nLogLoss: 0.00034703292888788734\nMean Per-Class Error: 1.2310289643529185e-05\nAUC: 0.9999978008850409\nAUCPR: 0.9999975406058657\nGini: 0.9999956017700817\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.9998410272152997\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------\n0      284308  7       0        (7.0/284315.0)\n1      0       284315  0        (0.0/284315.0)\nTotal  284308  284322  0        (7.0/568630.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.999841     0.999988  66\nmax f2                       0.999841     0.999995  66\nmax f0point5                 0.999841     0.99998   66\nmax accuracy                 0.999841     0.999988  66\nmax precision                1            1         0\nmax recall                   0.999841     1         66\nmax specificity              1            1         0\nmax absolute_mcc             0.999841     0.999975  66\nmax min_per_class_accuracy   0.999841     0.999975  66\nmax mean_per_class_accuracy  0.999841     0.999988  66\nmax tns                      1            284315    0\nmax fns                      1            202390    0\nmax fps                      1.42627e-07  284315    399\nmax tps                      0.999841     284315    66\nmax tnr                      1            1         0\nmax fnr                      1            0.711851  0\nmax fpr                      1.42627e-07  1         399\nmax tpr                      0.999841     1         66\n\nGains/Lift Table: Avg response rate: 50.00 %, avg score: 50.01 %\ngroup    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n1        0.0115365                   1                  2        2                  1                1            1                           1                   0.023073        0.023073                   100      100                0.023073\n2        0.0239752                   1                  2        2                  1                1            1                           1                   0.0248773       0.0479503                  100      100                0.0479503\n3        0.0395952                   1                  2        2                  1                1            1                           1                   0.03124         0.0791903                  100      100                0.0791903\n4        0.0531945                   1                  2        2                  1                1            1                           1                   0.0271987       0.106389                   100      100                0.106389\n5        0.104474                    1                  2        2                  1                1            1                           1                   0.102559        0.208948                   100      100                0.208948\n6        0.151923                    1                  2        2                  1                1            1                           1                   0.0948983       0.303846                   100      100                0.303846\n7        0.202161                    1                  2        2                  1                1            1                           1                   0.100477        0.404323                   100      100                0.404323\n8        0.300918                    0.999999           2        2                  1                0.999999     1                           1                   0.197513        0.601836                   100      100                0.601836\n9        0.400067                    0.999998           1.99996  1.99999            0.999982         0.999999     0.999996                    0.999999            0.198294        0.80013                    99.9965  99.9991            0.800127\n10       0.500012                    0.999841           1.99979  1.99995            0.999894         0.999987     0.999975                    0.999997            0.19987         1                          99.9789  99.9951            0.999975\n11       0.600353                    1.87e-06           0        1.66569            0                0.000529523  0.832843                    0.832949            0               1                          -100     66.5685            0.799293\n12       0.700257                    1.02e-06           0        1.42805            0                1.42028e-06  0.714024                    0.714115            0               1                          -100     42.8048            0.599486\n13       0.803433                    4e-07              0        1.24466            0                6.43974e-07  0.62233                     0.622409            0               1                          -100     24.4659            0.393134\n14       0.904356                    2.2e-07            0        1.10576            0                2.9427e-07   0.55288                     0.55295             0               1                          -100     10.5759            0.191288\n15       1                           1e-08              0        1                  0                1.48704e-07  0.5                         0.500064            0               1                          -100     0                  0\n\nCross-Validation Metrics Summary: \n                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\naccuracy                 0.999989     3.93238e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nauc                      0.999998     3.0045e-06   0.999993      0.999996      0.999999      1             1\nerr                      1.05517e-05  3.93238e-06  8.79306e-06   1.75861e-05   8.79306e-06   8.79306e-06   8.79306e-06\nerr_count                1.2          0.447214     1             2             1             1             1\nf0point5                 0.999983     6.29007e-06  0.999986      0.999972      0.999986      0.999986      0.999986\nf1                       0.999989     3.93131e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nf2                       0.999996     1.57248e-06  0.999996      0.999993      0.999996      0.999996      0.999996\nlift_top_group           2            0.000348185  2.00046       1.99979       2.00011       2.00011       1.99954\nlogloss                  0.000351323  0.000151033  0.000451642   0.000558287   0.000308915   0.00024597    0.000191799\nmax_per_class_error      2.11037e-05  7.86662e-06  1.75821e-05   3.5176e-05    1.75852e-05   1.75852e-05   1.75901e-05\nmcc                      0.999979     7.86452e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nmean_per_class_accuracy  0.999989     3.93329e-06  0.999991      0.999982      0.999991      0.999991      0.999991\nmean_per_class_error     1.05519e-05  3.93331e-06  8.79105e-06   1.7588e-05    8.7926e-06    8.7926e-06    8.79507e-06\nmse                      5.17228e-05  2.36595e-05  7.30121e-05   7.26092e-05   5.87986e-05   3.36802e-05   2.05139e-05\npr_auc                   0.999997     3.80841e-06  0.999991      0.999996      0.999999      1             1\nprecision                0.999979     7.86249e-06  0.999982      0.999965      0.999982      0.999982      0.999982\nr2                       0.999793     9.46379e-05  0.999708      0.99971       0.999765      0.999865      0.999918\nrecall                   1            0            1             1             1             1             1\nrmse                     0.0070133    0.00178057   0.00854471    0.00852111    0.00766802    0.00580346    0.00452922\nspecificity              0.999979     7.86664e-06  0.999982      0.999965      0.999982      0.999982      0.999982\n\nScoring History: \n     timestamp            duration           number_of_trees    training_rmse           training_logloss        training_auc        training_pr_auc     training_lift    training_classification_error\n---  -------------------  -----------------  -----------------  ----------------------  ----------------------  ------------------  ------------------  ---------------  -------------------------------\n     2023-05-17 07:19:55  12 min 24.175 sec  0.0                0.5                     0.6931471805594906      0.5                 0.5                 1.0              0.5\n     2023-05-17 07:20:00  12 min 29.378 sec  5.0                0.3027539076569943      0.3602735758590258      0.9999583736599278  0.9999549519021839  2.0              0.0003657914636934386\n     2023-05-17 07:20:04  12 min 33.804 sec  10.0               0.18463969334455507     0.20329722217602272     0.9999718745969037  0.9999686281391038  2.0              0.00017058544220319012\n     2023-05-17 07:20:09  12 min 38.447 sec  15.0               0.11410464082101325     0.11965766447485039     0.9999777823025563  0.9999752353590851  2.0              0.00014244763730369484\n     2023-05-17 07:20:13  12 min 42.894 sec  20.0               0.07138108330623394     0.07185105158083227     0.999980356446807   0.9999776805877443  2.0              0.00011255121959798112\n     2023-05-17 07:20:18  12 min 47.319 sec  25.0               0.046061955280494817    0.043845401522722725    0.9999806441006015  0.999976224745567   2.0              0.00010199954276067039\n     2023-05-17 07:20:22  12 min 51.737 sec  30.0               0.031112452481983334    0.027053597850049866    0.9999868172790677  0.9999849079339339  2.0              6.331006102386438e-05\n     2023-05-17 07:20:27  12 min 56.207 sec  35.0               0.022542550826428295    0.016914393938143465    0.9999870962361362  0.9999850721470551  2.0              5.627560979899056e-05\n     2023-05-17 07:20:31  13 min  0.873 sec  40.0               0.01766341943799046     0.010655517859075214    0.9999898275585523  0.9999876122116917  2.0              3.693086893058755e-05\n     2023-05-17 07:20:36  13 min  5.344 sec  45.0               0.014589120101518471    0.006795877655729194    0.9999930655673077  0.9999921776834312  2.0              2.9896417705713734e-05\n---  ---                  ---                ---                ---                     ---                     ---                 ---                 ---              ---\n     2023-05-17 07:21:40  14 min  9.354 sec  120.0              0.00065306377424895     3.16432556309842e-05    1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:44  14 min 13.724 sec  125.0              0.0005084018965388476   2.3808421309119888e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:48  14 min 17.850 sec  130.0              0.00038844359738230647  1.7968339872344618e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:52  14 min 21.987 sec  135.0              0.0003073750563567389   1.3719138034083516e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:21:57  14 min 26.099 sec  140.0              0.0002405969824860052   1.0488524185782484e-05  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:01  14 min 30.231 sec  145.0              0.00018904533995990288  7.854240501567559e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:05  14 min 34.370 sec  150.0              0.00014462769065615446  5.797557939228732e-06   1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:09  14 min 38.566 sec  155.0              0.00010567787499643689  4.2219134693428804e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:13  14 min 43.001 sec  160.0              7.900020814711673e-05   3.1864422688417992e-06  1.0                 1.0                 2.0              0.0\n     2023-05-17 07:22:16  14 min 45.568 sec  163.0              7.087070508518194e-05   2.7328193386006475e-06  1.0                 1.0                 2.0              0.0\n[34 rows x 10 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance      percentage\n----------  ---------------------  ---------------------  ---------------------\nV14         249937.859375          1.0                    0.35021734738652266\nV10         212824.109375          0.8515080904797399     0.2982129047259776\nV11         77671.3359375          0.31076258767569914    0.10883444912275503\nV4          36254.71875            0.14505493021609184    0.050800752885616834\nV17         28100.43359375         0.11242968017737909    0.03937482435923682\nV12         12264.8359375          0.04907154109493341    0.017185704954436318\nV26         9074.3583984375        0.03630645801772103    0.012715151419966406\nV3          8412.37109375          0.03365785045445358    0.011787563104891001\nV13         8358.12109375          0.03344079650298077    0.01171154704576643\nV8          6165.67724609375       0.02466884073309972    0.008639455964646785\n---         ---                    ---                    ---\nV9          3120.103515625         0.01248351699669349    0.004371944208636565\nV22         3079.070556640625      0.01231934435359339    0.004314448101056613\nV23         2943.304443359375      0.011776144881449596   0.004124210222820654\nV6          2751.612060546875      0.01100918471266264    0.003855607466956967\nV21         2601.30712890625       0.010407815508267273   0.003644997539393678\nV5          2238.633544921875      0.008956760494467907   0.0031368129015489493\nV24         1781.650146484375      0.007128372432010132   0.0024964796843218034\nV27         1344.9044189453125     0.0053809551794530425  0.0018845038493538148\nV28         1290.6734619140625     0.005163977418793409   0.00180851447357373\nV2          1205.940185546875      0.004824960046319013   0.0016897847086677982\n[29 rows x 4 columns]\n\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/GBM_1_AutoML_2_20230517_63622'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Get metrics for leaderboard","metadata":{}},{"cell_type":"code","source":"# Get leaderboard with all possible columns\nlb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\nlb","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}